{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys, os, logging\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "import optuna\n",
    "\n",
    "# Source papkasini qo'shish\n",
    "source_path = \"../Source\"\n",
    "if source_path not in sys.path:\n",
    "    sys.path.append(source_path)\n",
    "from preprocessing import Cleaner, Encoder, Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_path = r\"C:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\Log\\data_loader.log\"\n",
    "logging.basicConfig(filename=log_path, filemode='a',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "csv_path = r\"C:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\Data\\Raw_Data\\hotel_bookings_updated_2024.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "logging.info(f\"Fayl o'qildi: {len(df)} satr, {len(df.columns)} ustun\")\n",
    "\n",
    "y = df['is_canceled']\n",
    "X = df.drop(columns=['is_canceled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d675ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58b6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = Cleaner(); cleaner.fit(X_train)\n",
    "X_train_clean = cleaner.transform(X_train)\n",
    "X_test_clean = cleaner.transform(X_test)\n",
    "\n",
    "encoder = Encoder(max_unique=5); encoder.fit(X_train_clean)\n",
    "X_train_enc = encoder.transform(X_train_clean)\n",
    "X_test_enc = encoder.transform(X_test_clean)\n",
    "\n",
    "scaler = Scaler(); scaler.fit(X_train_enc)\n",
    "X_train_final = scaler.transform(X_train_enc)\n",
    "X_test_final = scaler.transform(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e82c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcd640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "models = {\"Logistic Regression\": lr, \"Decision Tree\": dt, \"Random Forest\": rf, \"KNN\": knn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b070b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.5824</td>\n",
       "      <td>0.4203</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.3735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                               Best_Params  Accuracy  \\\n",
       "0  Logistic Regression              {'C': 0.01, 'penalty': 'l2'}    1.0000   \n",
       "1        Decision Tree  {'max_depth': 3, 'min_samples_split': 2}    1.0000   \n",
       "2        Random Forest      {'max_depth': 5, 'n_estimators': 50}    1.0000   \n",
       "3                  KNN                        {'n_neighbors': 3}    0.5824   \n",
       "\n",
       "   Precision  Recall  F1-Score  \n",
       "0     1.0000  1.0000    1.0000  \n",
       "1     1.0000  1.0000    1.0000  \n",
       "2     1.0000  1.0000    1.0000  \n",
       "3     0.4203  0.3361    0.3735  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'Logistic Regression': {'C':[0.01,0.1,1,10], 'penalty':['l2']},\n",
    "    'Decision Tree': {'max_depth':[3,5,10,None], 'min_samples_split':[2,5,10]},\n",
    "    'Random Forest': {'n_estimators':[50,100,200], 'max_depth':[5,10,None]},\n",
    "    'KNN': {'n_neighbors':[3,5,7,10]}\n",
    "}\n",
    "\n",
    "grid_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    grid = GridSearchCV(model, param_grid[name], scoring='f1', cv=5, n_jobs=-1)\n",
    "    grid.fit(X_train_bal, y_train_bal)\n",
    "    y_pred = grid.predict(X_test_final)\n",
    "    grid_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_Params\": grid.best_params_,\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred),4),\n",
    "        \"Precision\": round(precision_score(y_test, y_pred),4),\n",
    "        \"Recall\": round(recall_score(y_test, y_pred),4),\n",
    "        \"F1-Score\": round(f1_score(y_test, y_pred),4)\n",
    "    })\n",
    "\n",
    "grid_df = pd.DataFrame(grid_results)\n",
    "grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23697a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'min_samples_split': 5, 'max_depth': None}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': None}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.5824</td>\n",
       "      <td>0.4203</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.3735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                  Best_Params  Accuracy  \\\n",
       "0  Logistic Regression                                  {'C': 0.01}    1.0000   \n",
       "1        Decision Tree  {'min_samples_split': 5, 'max_depth': None}    1.0000   \n",
       "2        Random Forest     {'n_estimators': 100, 'max_depth': None}    1.0000   \n",
       "3                  KNN                           {'n_neighbors': 3}    0.5824   \n",
       "\n",
       "   Precision  Recall  F1-Score  \n",
       "0     1.0000  1.0000    1.0000  \n",
       "1     1.0000  1.0000    1.0000  \n",
       "2     1.0000  1.0000    1.0000  \n",
       "3     0.4203  0.3361    0.3735  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'Logistic Regression': {'C':[0.01,0.1,1,10]},\n",
    "    'Decision Tree': {'max_depth':[3,5,10,None], 'min_samples_split':[2,5,10]},\n",
    "    'Random Forest': {'n_estimators':[50,100,200], 'max_depth':[5,10,None]},\n",
    "    'KNN': {'n_neighbors':[3,5,7,10]}\n",
    "}\n",
    "\n",
    "random_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    rand = RandomizedSearchCV(model, param_distributions=param_dist[name], n_iter=5, scoring='f1', cv=5, n_jobs=-1, random_state=42)\n",
    "    rand.fit(X_train_bal, y_train_bal)\n",
    "    y_pred = rand.predict(X_test_final)\n",
    "    random_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_Params\": rand.best_params_,\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred),4),\n",
    "        \"Precision\": round(precision_score(y_test, y_pred),4),\n",
    "        \"Recall\": round(recall_score(y_test, y_pred),4),\n",
    "        \"F1-Score\": round(f1_score(y_test, y_pred),4)\n",
    "    })\n",
    "\n",
    "random_df = pd.DataFrame(random_results)\n",
    "random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc1a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 16:58:32,939] A new study created in memory with name: no-name-3808f573-15de-4978-b313-4aee51651367\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-12-20 16:58:51,817] Trial 0 finished with value: 1.0 and parameters: {'C': 0.014022689411892306}. Best is trial 0 with value: 1.0.\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-12-20 16:59:11,083] Trial 1 finished with value: 1.0 and parameters: {'C': 0.015895848637427136}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 16:59:20,776] Trial 2 finished with value: 1.0 and parameters: {'C': 0.309756631014874}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 16:59:34,781] Trial 3 finished with value: 1.0 and parameters: {'C': 0.0768692911586287}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 16:59:39,842] Trial 4 finished with value: 1.0 and parameters: {'C': 1.4431866586249211}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:00:03,275] Trial 5 finished with value: 1.0 and parameters: {'C': 0.0799543014656717}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:00:20,484] Trial 6 finished with value: 1.0 and parameters: {'C': 0.08181179856906179}. Best is trial 0 with value: 1.0.\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-12-20 17:00:39,485] Trial 7 finished with value: 1.0 and parameters: {'C': 0.01661751956526328}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:00:46,516] Trial 8 finished with value: 1.0 and parameters: {'C': 0.5770495637994294}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:02,983] Trial 9 finished with value: 1.0 and parameters: {'C': 0.027253168622161743}. Best is trial 0 with value: 1.0.\n",
      "c:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-12-20 17:01:21,731] A new study created in memory with name: no-name-2eb7f0aa-f21c-4b1c-b555-89d526c9f06e\n",
      "[I 2025-12-20 17:01:21,893] Trial 0 finished with value: 1.0 and parameters: {'max_depth': 11, 'min_samples_split': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:22,048] Trial 1 finished with value: 1.0 and parameters: {'max_depth': 6, 'min_samples_split': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:22,215] Trial 2 finished with value: 1.0 and parameters: {'max_depth': 15, 'min_samples_split': 10}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:22,370] Trial 3 finished with value: 1.0 and parameters: {'max_depth': 9, 'min_samples_split': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:22,518] Trial 4 finished with value: 1.0 and parameters: {'max_depth': 11, 'min_samples_split': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:22,666] Trial 5 finished with value: 1.0 and parameters: {'max_depth': 11, 'min_samples_split': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:22,822] Trial 6 finished with value: 1.0 and parameters: {'max_depth': 15, 'min_samples_split': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:22,973] Trial 7 finished with value: 1.0 and parameters: {'max_depth': 10, 'min_samples_split': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:23,123] Trial 8 finished with value: 1.0 and parameters: {'max_depth': 10, 'min_samples_split': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:23,274] Trial 9 finished with value: 1.0 and parameters: {'max_depth': 12, 'min_samples_split': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:23,433] A new study created in memory with name: no-name-d33363b2-100d-4475-b174-dbca326469cd\n",
      "[I 2025-12-20 17:01:30,085] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 155, 'max_depth': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:38,521] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 197, 'max_depth': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:41,454] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 61, 'max_depth': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:47,726] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 131, 'max_depth': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:01:54,868] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 154, 'max_depth': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:02:01,232] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 149, 'max_depth': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:02:08,878] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 152, 'max_depth': 14}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:02:16,730] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 152, 'max_depth': 17}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:02:27,387] Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 199, 'max_depth': 19}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:02:30,904] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 65, 'max_depth': 19}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-20 17:02:37,452] A new study created in memory with name: no-name-f937f2a3-6b88-4fe4-8cdd-1bd98aa95c9e\n",
      "[I 2025-12-20 17:02:42,994] Trial 0 finished with value: 0.2769090633065128 and parameters: {'n_neighbors': 6}. Best is trial 0 with value: 0.2769090633065128.\n",
      "[I 2025-12-20 17:02:48,596] Trial 1 finished with value: 0.2788309040102711 and parameters: {'n_neighbors': 10}. Best is trial 1 with value: 0.2788309040102711.\n",
      "[I 2025-12-20 17:02:54,363] Trial 2 finished with value: 0.3483012904924941 and parameters: {'n_neighbors': 7}. Best is trial 2 with value: 0.3483012904924941.\n",
      "[I 2025-12-20 17:03:00,076] Trial 3 finished with value: 0.34431741761936785 and parameters: {'n_neighbors': 11}. Best is trial 2 with value: 0.3483012904924941.\n",
      "[I 2025-12-20 17:03:05,670] Trial 4 finished with value: 0.3154481132075472 and parameters: {'n_neighbors': 14}. Best is trial 2 with value: 0.3483012904924941.\n",
      "[I 2025-12-20 17:03:11,791] Trial 5 finished with value: 0.28950524737631184 and parameters: {'n_neighbors': 12}. Best is trial 2 with value: 0.3483012904924941.\n",
      "[I 2025-12-20 17:03:17,877] Trial 6 finished with value: 0.2759769766737352 and parameters: {'n_neighbors': 8}. Best is trial 2 with value: 0.3483012904924941.\n",
      "[I 2025-12-20 17:03:23,954] Trial 7 finished with value: 0.35779325120514194 and parameters: {'n_neighbors': 13}. Best is trial 7 with value: 0.35779325120514194.\n",
      "[I 2025-12-20 17:03:30,621] Trial 8 finished with value: 0.28950524737631184 and parameters: {'n_neighbors': 12}. Best is trial 7 with value: 0.35779325120514194.\n",
      "[I 2025-12-20 17:03:37,179] Trial 9 finished with value: 0.37970300326296863 and parameters: {'n_neighbors': 15}. Best is trial 9 with value: 0.37970300326296863.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.014022689411892306}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 4}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'n_estimators': 155, 'max_depth': 6}</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.4619</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>0.3797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                                Best_Params  Accuracy  \\\n",
       "0  Logistic Regression                {'C': 0.014022689411892306}    1.0000   \n",
       "1        Decision Tree  {'max_depth': 11, 'min_samples_split': 4}    1.0000   \n",
       "2        Random Forest      {'n_estimators': 155, 'max_depth': 6}    1.0000   \n",
       "3                  KNN                        {'n_neighbors': 15}    0.6099   \n",
       "\n",
       "   Precision  Recall  F1-Score  \n",
       "0     1.0000  1.0000    1.0000  \n",
       "1     1.0000  1.0000    1.0000  \n",
       "2     1.0000  1.0000    1.0000  \n",
       "3     0.4619  0.3223    0.3797  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_results = []\n",
    "\n",
    "def objective(trial, model_name):\n",
    "    if model_name=='Logistic Regression':\n",
    "        C = trial.suggest_float('C', 0.01, 10.0, log=True)\n",
    "        model = LogisticRegression(C=C, max_iter=1000)\n",
    "    elif model_name=='Decision Tree':\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    elif model_name=='Random Forest':\n",
    "        n_estimators = trial.suggest_int('n_estimators',50,200)\n",
    "        max_depth = trial.suggest_int('max_depth',5,20)\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    elif model_name=='KNN':\n",
    "        n_neighbors = trial.suggest_int('n_neighbors',3,15)\n",
    "        model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    model.fit(X_train_bal, y_train_bal)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    return f1_score(y_test, y_pred)\n",
    "\n",
    "for name in models.keys():\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, name), n_trials=10)\n",
    "    best_params = study.best_params\n",
    "    # Train best model\n",
    "    if name=='Logistic Regression':\n",
    "        best_model = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "    elif name=='Decision Tree':\n",
    "        best_model = DecisionTreeClassifier(max_depth=best_params['max_depth'], min_samples_split=best_params['min_samples_split'], random_state=42)\n",
    "    elif name=='Random Forest':\n",
    "        best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], random_state=42)\n",
    "    elif name=='KNN':\n",
    "        best_model = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'])\n",
    "    \n",
    "    best_model.fit(X_train_bal, y_train_bal)\n",
    "    y_pred = best_model.predict(X_test_final)\n",
    "    optuna_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_Params\": best_params,\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred),4),\n",
    "        \"Precision\": round(precision_score(y_test, y_pred),4),\n",
    "        \"Recall\": round(recall_score(y_test, y_pred),4),\n",
    "        \"F1-Score\": round(f1_score(y_test, y_pred),4)\n",
    "    })\n",
    "\n",
    "optuna_df = pd.DataFrame(optuna_results)\n",
    "optuna_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d480e1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'C:\\\\Users\\\\Rasulbek907\\\\Desktop\\\\Hotel Booking Cancellation Prediction\\\\Models\\\\0    Logistic Regression\\n0    Logistic Regression\\n0    Logistic Regression\\nName: Model, dtype: objectpipeline_best_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m os.makedirs(save_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m save_path = os.path.join(save_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_name.replace(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mpipeline_best_model.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m best_model_name, save_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\mpvenv\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(value, filename, compress, protocol)\u001b[39m\n\u001b[32m    597\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    600\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: 'C:\\\\Users\\\\Rasulbek907\\\\Desktop\\\\Hotel Booking Cancellation Prediction\\\\Models\\\\0    Logistic Regression\\n0    Logistic Regression\\n0    Logistic Regression\\nName: Model, dtype: objectpipeline_best_model.pkl'"
     ]
    }
   ],
   "source": [
    "all_results = pd.concat([grid_df, random_df, optuna_df])\n",
    "best_idx = all_results['F1-Score'].idxmax()\n",
    "best_model_info = all_results.loc[best_idx]\n",
    "best_model_name = best_model_info['Model']\n",
    "save_dir = r\"C:\\Users\\Rasulbek907\\Desktop\\Hotel Booking Cancellation Prediction\\Models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, f\"{best_model_name.replace(' ','_')}pipeline_best_model.pkl\")\n",
    "joblib.dump(best_model, save_path)\n",
    "best_model_name, save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16543ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "for i, row in all_results.iterrows():\n",
    "    row_colors = []\n",
    "    for metric in ['Accuracy','Precision','Recall','F1-Score']:\n",
    "        if row[metric]>=0.8:\n",
    "            row_colors.append('lightgreen')\n",
    "        elif row[metric]<0.6:\n",
    "            row_colors.append('lightcoral')\n",
    "        else:\n",
    "            row_colors.append('white')\n",
    "    colors.append(['white'] + row_colors)\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(all_results.columns), fill_color='paleturquoise', align='center'),\n",
    "    cells=dict(values=[all_results[col] for col in all_results.columns], fill_color=colors, align='center'))\n",
    "])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d510be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
